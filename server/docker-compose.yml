# The environment variables such as 
# ${FACE_THRESHOLD} and ${API_KEY} should
# reside in a .env file along side docker-compose.yaml
#
# To speed up build when buildkit is not yet enabled by default,
# COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1 docker-compose build

version: '2.3'
services:
  gabriel-server:
    #image: cmusatyalab/openscout:${OPENSCOUT_TAG}
    build: .
    container_name: gabriel-server
    ports:
      - "9099:9099"
      - "5555:5555"
    entrypoint: ["openscout"]
    restart: unless-stopped
    networks:
      - openscout-net

  http-server:
    image: httpd:2.4
    container_name: http-server
    ports:
      - "${HTTP_PORT}:80"
    restart: unless-stopped
    networks:
      - openscout-net
    volumes:
      - ./openscout-vol:/usr/local/apache2/htdocs

  face-engine:
    #image: cmusatyalab/openscout:${OPENSCOUT_TAG}
    build: .
    container_name: openscout-face-engine
    restart: unless-stopped
    privileged: true
    entrypoint: ["openscout-face-engine", "--endpoint", "http://openface-service:5000", "--threshold", "${FACE_THRESHOLD}", "${STORE}"]
    #to use MS Face Cognitive Service, make this the entrypoint instead and use the ms-face-server container...
    #entrypoint: ["openscout-face-engine", "--msface", "--endpoint", "http://ms-face-service:5000","--apikey", "${API_KEY}", "--threshold", "${FACE_THRESHOLD}"]
    volumes:
      - ./openscout-vol:/openscout-server/images/
      - training-vol:/openscout-server/training/
    depends_on:
      - gabriel-server
      - openface-service
      #- ms-face-service
    networks:
      - openscout-net
      - elk
    environment:
      - WEBSERVER=${WEBSERVER_URL}:${HTTP_PORT}

  object-engine:
    #image: cmusatyalab/openscout:${OPENSCOUT_TAG}
    build: .
    container_name: openscout-object-engine
    restart: unless-stopped
    privileged: true
    entrypoint: ["openscout-object-engine", "--model", "${DNN}", "--threshold", "${OBJ_THRESHOLD}", "--exclude", "${EXCLUSIONS}", "${STORE}"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./models:/openscout-server/models/
      - ./openscout-vol:/openscout-server/images/
    depends_on:
      - gabriel-server
    networks:
      - openscout-net
      - elk
    environment:
       - WEBSERVER=${WEBSERVER_URL}:${HTTP_PORT}
    #  - TF_FORCE_GPU_ALLOW_GROWTH=true #the following environment variable may be necessary if your GPU only has a modest (~2GB) amount of RAM
    #  - CUDA_VISIBLE_DEVICES=-1 #set this if you want to force CPU only

  ocr-engine:
    build: .
    container_name: openscout-ocr-engine
    restart: unless-stopped
    privileged: true
    entrypoint: ["openscout-ocr-engine", "${STORE}"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./openscout-vol:/openscout-server/images/
    depends_on:
      - gabriel-server
    networks:
      - openscout-net
      - elk
    environment:
      - WEBSERVER=${WEBSERVER_URL}:${HTTP_PORT}

# OpenFace is the default for face recognition
  openface-service:
    image: cmusatyalab/openface
    container_name: openface-service
    ports:
      - "5002:5000"
    restart: unless-stopped
    privileged: true
    entrypoint: ["python", "/root/openface-rest.py", "/openscout-server/training/"]
    volumes:
      - training-vol:/openscout-server/training/
    networks:
      - openscout-net

# OpenLLM is the default for LLM
  openllm-service:
    image: local/server_llama.cpp:light-cuda 
    container_name: openllm-service
    ports:
      - "5001:5000"
    restart: unless-stopped
    privileged: true
    entrypoint: [ "python3", "/app/server.py" ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - /home/ubuntu/blake/llama.cpp/Llama-2-13B-Ensemble-v6-GGUF:/models
    networks:
      - openscout-net

# or the MS Face Cognitive Server can be used (Azure Account Required)
  # ms-face-service:
  #   image: containerpreview.azurecr.io/microsoft/cognitive-services-face
  #   container_name: ms-face-service
  #   restart: unless-stopped
  #   ports:
  #     - "5000:5000"
  #   networks:
  #     - openscout-net
  #   cpus: '1.0'
  #   mem_reservation: 4gb
  #   environment:
  #     - Eula=accept
  #     - Billing=${BILLING_ENDPOINT}
  #     - ApiKey=${API_KEY}
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELK_VERSION}
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - 9200:9200
    restart: unless-stopped
    privileged: true
    networks:
      - elk
  kibana:
    image: docker.elastic.co/kibana/kibana:${ELK_VERSION}
    container_name: kibana
    ports:
      - 5601:5601
    restart: unless-stopped
    privileged: true
    networks:
      - elk
    depends_on:
      - elasticsearch
  logstash:
    image: docker.elastic.co/logstash/logstash:${ELK_VERSION}
    container_name: logstash
    ports:
      - 5044:5044
    restart: unless-stopped
    privileged: true
    networks:
      - elk
    volumes:
      - ./elk/pipeline/:/usr/share/logstash/pipeline/
    depends_on:
      - elasticsearch
networks:
  openscout-net:
    ipam:
      driver: default
      config:
        - subnet: 10.0.0.0/8
  elk:
volumes:
  training-vol:
